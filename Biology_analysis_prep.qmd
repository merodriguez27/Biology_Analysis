---
title: "Biology Analysis Prep"
format: html
editor: visual
---

```{r}
#Load Packages Necessary

library(readxl)
library(dplyr)
library(irr)
```

```{r}
# Compute percent agreement per criterion
percent_agreement <- data |>
  group_by(Criterion) |>
  summarise(
    percent_agreement = mean(Rater1 == Rater2, na.rm = TRUE) * 100,
    n = sum(!is.na(Rater1) & !is.na(Rater2)),  # number of valid comparisons
    .groups = "drop"
  )
print(percent_agreement)
```

```{r}
library(ggplot2)
actual_criterion_numbers <- c(1, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 5, 6, 8, 9)

percent_agreement <- percent_agreement |>
  mutate(Criterion_Label = paste0("C", actual_criterion_numbers))

percent_agreement <- percent_agreement |>
  mutate(
    Agreement_Level = case_when(
      percent_agreement >= 90 ~ "Excellent",
      percent_agreement >= 75 ~ "Acceptable",
      TRUE ~ "Low"
    ),
    Agreement_Level = factor(Agreement_Level, levels = c("Excellent", "Acceptable", "Low"))
  )

ggplot(percent_agreement, aes(x = reorder(Criterion_Label, percent_agreement), y = percent_agreement, fill = Agreement_Level)) +
  geom_col() +
  geom_text(aes(label = sprintf("%.1f%%", percent_agreement)), hjust = -0.1, size = 3) +
  coord_flip() +
  geom_hline(yintercept = 75, linetype = "dashed", color = "red") +
  geom_hline(yintercept = 90, linetype = "dashed", color = "darkgreen") +
  scale_fill_manual(values = c("Excellent" = "#1b9e77", "Acceptable" = "#d95f02", "Low" = "#7570b3")) +
  labs(
    title = "Percent Agreement by Criterion",
    subtitle = "Two Human Evaluations of Biology Questions",
    x = NULL,
    y = "Percent Agreement",
    fill = "Agreement Level"
  ) +
  expand_limits(y = 105) +
  theme_minimal(base_size = 14)

```

```{r}
# Load files
chatgpt <- read_excel("final_7.16_ChatGPT Question Evaluation.xlsx")
maylynn <- read_excel("Biology Question Evaluation (Maylynn) (2).xlsx")

# Clean column names if needed
names(chatgpt) <- trimws(names(chatgpt))
names(maylynn) <- trimws(names(maylynn))

# Identify shared evaluation criteria (i.e., common column names)
shared_criteria <- intersect(names(chatgpt), names(maylynn))

# Initialize an empty data frame to store percent agreement
percent_agreement <- data.frame()

# Loop over each shared criterion and calculate agreement
for (criterion in shared_criteria) {
  rater1 <- chatgpt[[criterion]]
  rater2 <- maylynn[[criterion]]
  
  valid <- !is.na(rater1) & !is.na(rater2)
  agreement <- mean(rater1[valid] == rater2[valid]) * 100
  n <- sum(valid)
  
  percent_agreement <- rbind(percent_agreement, data.frame(
    Criterion = criterion,
    percent_agreement = agreement,
    n = n
  ))
}

# View results
print(percent_agreement)

```

